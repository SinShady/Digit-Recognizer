{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "The goal of this project is to correctly identify digits using the MNIST (\"Modified National Institute of Standards and Technology\") dataset, which includes tens of thousands of handwritten images. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "Practice Skills:\n",
    "<br> Computer vision fundamentals including simple neural networks\n",
    "<br> Classification methods such as SVM and K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:08.316337Z",
     "start_time": "2021-03-12T22:02:08.299310Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-09T17:25:43.119219Z",
     "start_time": "2021-03-09T17:25:43.096221Z"
    }
   },
   "source": [
    "### Data Description\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "\n",
    "`000 001 002 003 ... 026 027\n",
    "028 029 030 031 ... 054 055\n",
    "056 057 058 059 ... 082 083\n",
    " |   |   |   |  ...  |   |\n",
    "728 729 730 731 ... 754 755\n",
    "756 757 758 759 ... 782 783`\n",
    "\n",
    "The test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\n",
    "\n",
    "Your submission file should be in the following format: For each of the 28000 images in the test set, output a single line containing the ImageId and the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\n",
    "\n",
    "ImageId,Label\n",
    "1,3\n",
    "2,7\n",
    "3,8 \n",
    "(27997 more lines)\n",
    "The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Download\n",
    "In order to run the following command, kaggle must be installed with `'pip install kaggle'` and an API token must be in your directory `'.kaggle/kaggle.json'`. You can get this API token by going to your kaggle account page and clicking \"Create New API Token\". For a detailed instructions on how to do this, visit https://www.kaggle.com/docs/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:09.177323Z",
     "start_time": "2021-03-12T22:02:09.171323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset from kaggle into the data folder\n",
    "# ! kaggle competitions download -c digit-recognizer -p ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:10.147579Z",
     "start_time": "2021-03-12T22:02:10.138572Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Extract the zipfile\n",
    "# with zipfile.ZipFile(\"../data/digit-recognizer.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:12.857026Z",
     "start_time": "2021-03-12T22:02:10.602839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a pandas dataframe from train csv\n",
    "data = '../data/train.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:12.921116Z",
     "start_time": "2021-03-12T22:02:12.858014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Use .info() to see the size of data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:12.953126Z",
     "start_time": "2021-03-12T22:02:12.923116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       785\n",
       "unique        1\n",
       "top       False\n",
       "freq        785\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values so we can move forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:02:14.322926Z",
     "start_time": "2021-03-12T22:02:14.130366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sin City\\anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the distribution of labels in our training data\n",
    "# Our labels will be the numbers 0-9\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.countplot(df['label'], palette = 'muted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:03:58.867560Z",
     "start_time": "2021-03-12T22:03:58.110452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into target(label) and features\n",
    "y = df['label']\n",
    "X = df.drop('label', axis=1)\n",
    "\n",
    "# OneHotEncode labels for our model to understand\n",
    "y = to_categorical(y, num_classes = 10)\n",
    "\n",
    "# Normalize the values from 0 to 1\n",
    "X = X/255\n",
    "\n",
    "# Split intro train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:04:54.252630Z",
     "start_time": "2021-03-12T22:04:53.922756Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:04:54.833021Z",
     "start_time": "2021-03-12T22:04:54.810986Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:04:58.264713Z",
     "start_time": "2021-03-12T22:04:55.842565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704/704 [==============================] - 1s 1ms/step - loss: 0.9520 - accuracy: 0.7014 - val_loss: 0.4859 - val_accuracy: 0.8634\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 1s 795us/step - loss: 0.4370 - accuracy: 0.8750 - val_loss: 0.3885 - val_accuracy: 0.8907\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 1s 799us/step - loss: 0.3627 - accuracy: 0.8953 - val_loss: 0.3361 - val_accuracy: 0.9064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b19d4c5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T22:05:50.258859Z",
     "start_time": "2021-03-12T22:05:50.066866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 823us/step - loss: 0.3423 - accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
